{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "700d66e2-8480-487b-a32a-5126d9653e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2731054686009884, Accuracy: 89.33%\n",
      "Epoch 2, Loss: 0.2093217857182026, Accuracy: 92.89%\n",
      "Epoch 3, Loss: 0.2727052979171276, Accuracy: 90.67%\n",
      "Epoch 4, Loss: 0.22591569274663925, Accuracy: 90.67%\n",
      "Epoch 5, Loss: 0.1403079628944397, Accuracy: 93.33%\n",
      "Epoch 6, Loss: 0.14155160263180733, Accuracy: 95.11%\n",
      "Epoch 7, Loss: 0.2088945060968399, Accuracy: 92.44%\n",
      "Epoch 8, Loss: 0.1017427071928978, Accuracy: 96.44%\n",
      "Epoch 9, Loss: 0.2026631087064743, Accuracy: 92.44%\n",
      "Epoch 10, Loss: 0.31031903252005577, Accuracy: 94.67%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
    "from transformers import ViTModel\n",
    "from torch.optim import Adam\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 1. تعریف Dataset برای Triplet ها\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.classes = dataset.classes\n",
    "        self.class_to_indices = {cls: np.where(np.array(dataset.targets) == idx)[0] for idx, cls in enumerate(self.classes)}\n",
    "        self.transform = Compose([\n",
    "            Resize((224, 224)),  # تغییر اندازه تصاویر به 224x224\n",
    "            ToTensor(),  # تبدیل تصاویر به تانسور\n",
    "            Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # نرمال سازی\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_path, anchor_label = self.dataset.samples[idx]  # مسیر فایل و برچسب\n",
    "\n",
    "        # انتخاب Positive (همان کلاس)\n",
    "        positive_idx = np.random.choice(self.class_to_indices[self.classes[anchor_label]])\n",
    "        positive_path, _ = self.dataset.samples[positive_idx]\n",
    "\n",
    "        # انتخاب Negative (کلاس متفاوت)\n",
    "        negative_label = np.random.choice([cls for cls in self.classes if cls != self.classes[anchor_label]])\n",
    "        negative_idx = np.random.choice(self.class_to_indices[negative_label])\n",
    "        negative_path, _ = self.dataset.samples[negative_idx]\n",
    "\n",
    "        # پیش پردازش تصاویر\n",
    "        anchor_image = self.transform(Image.open(anchor_path).convert(\"RGB\"))\n",
    "        positive_image = self.transform(Image.open(positive_path).convert(\"RGB\"))\n",
    "        negative_image = self.transform(Image.open(negative_path).convert(\"RGB\"))\n",
    "\n",
    "        return anchor_image, positive_image, negative_image\n",
    "\n",
    "# 2. تعریف Attention Layer\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(feature_dim, feature_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feature_dim // 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, feature_dim)\n",
    "        attention_weights = self.attention(x)  # (batch_size, sequence_length, 1)\n",
    "        weighted_features = x * attention_weights  # (batch_size, sequence_length, feature_dim)\n",
    "        return weighted_features.sum(dim=1)  # (batch_size, feature_dim)\n",
    "\n",
    "# 3. تعریف مدل با Attention Mechanism\n",
    "class ViTWithAttention(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(ViTWithAttention, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained(model_name)\n",
    "        self.attention = AttentionLayer(self.vit.config.hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(x)\n",
    "        last_hidden_state = outputs.last_hidden_state  # (batch_size, sequence_length, hidden_size)\n",
    "        features = self.attention(last_hidden_state)  # (batch_size, hidden_size)\n",
    "        return features\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        # استخراج ویژگی ها (embeddings)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.vit(x)\n",
    "            return outputs.last_hidden_state.mean(dim=1)  # میانگین گیری از توکن ها\n",
    "\n",
    "# 4. تعریف Triplet Loss\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        distance_positive = F.pairwise_distance(anchor, positive)\n",
    "        distance_negative = F.pairwise_distance(anchor, negative)\n",
    "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean()\n",
    "\n",
    "# 5. بارگذاری داده ها از پوشه ها\n",
    "data_dir = 'f:/Meysam-Khodarahi/PlantDiseaseDiagnosisFewShotLearning/siamese_triplet_net/src/dataset'\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# بارگذاری داده ها با ImageFolder\n",
    "train_dataset = ImageFolder(train_dir)\n",
    "val_dataset = ImageFolder(val_dir)\n",
    "test_dataset = ImageFolder(test_dir)\n",
    "\n",
    "# ایجاد TripletDataset\n",
    "train_triplet_dataset = TripletDataset(train_dataset)\n",
    "train_loader = DataLoader(train_triplet_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 6. تعریف مدل، Optimizer و Loss Function\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "model = ViTWithAttention(model_name)\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "triplet_loss = TripletLoss(margin=1.0)\n",
    "\n",
    "# 7. آموزش مدل و محاسبه Accuracy\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        anchor, positive, negative = batch\n",
    "\n",
    "        # استخراج ویژگی ها (embeddings)\n",
    "        anchor_features = model(anchor)\n",
    "        positive_features = model(positive)\n",
    "        negative_features = model(negative)\n",
    "\n",
    "        # محاسبه ی loss\n",
    "        loss = triplet_loss(anchor_features, positive_features, negative_features)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # محاسبه accuracy\n",
    "        distance_positive = F.pairwise_distance(anchor_features, positive_features)\n",
    "        distance_negative = F.pairwise_distance(anchor_features, negative_features)\n",
    "        predictions = (distance_positive < distance_negative).float()  # 1 اگر درست، 0 اگر نادرست\n",
    "        correct += predictions.sum().item()\n",
    "        total += predictions.size(0)\n",
    "\n",
    "        # به روزرسانی مدل\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader)}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 8. ذخیره‌سازی مدل Fine-Tuned\n",
    "torch.save(model.state_dict(), \"f:/Meysam-Khodarahi/PlantDiseaseDiagnosisFewShotLearning/siamese_triplet_net/vitWithAttentionState.pth\")\n",
    "torch.save(model, \"f:/Meysam-Khodarahi/PlantDiseaseDiagnosisFewShotLearning/siamese_triplet_net/vitWithAttention.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# فرض بر این است که test_loader داده‌های تست را می‌گیرد\n",
    "# و مدل قبلاً آموزش دیده است.\n",
    "\n",
    "def evaluate_triplet_model(model, test_loader, device):\n",
    "    model.eval()  # مدل را در حالت ارزیابی قرار می‌دهیم.\n",
    "    \n",
    "    y_true = []  # برای ذخیره برچسب‌های واقعی\n",
    "    y_pred = []  # برای ذخیره پیش‌بینی‌ها\n",
    "    \n",
    "    with torch.no_grad():  # بدون محاسبه گرادیان‌ها\n",
    "        for anchor, positive, negative in test_loader:\n",
    "            # انتقال داده‌ها به دستگاه (GPU یا CPU)\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "            # استخراج ویژگی‌ها (embeddings)\n",
    "            anchor_features = model.get_embedding(anchor)\n",
    "            positive_features = model.get_embedding(positive)\n",
    "            negative_features = model.get_embedding(negative)\n",
    "\n",
    "            # محاسبه فاصله‌ها\n",
    "            distance_positive = F.pairwise_distance(anchor_features, positive_features)\n",
    "            distance_negative = F.pairwise_distance(anchor_features, negative_features)\n",
    "\n",
    "            # پیش‌بینی‌ها (پیش‌بینی 1 اگر فاصله مثبت کمتر از منفی باشد)\n",
    "            predictions = (distance_positive < distance_negative).float()\n",
    "\n",
    "            # اضافه کردن برچسب‌ها و پیش‌بینی‌ها به لیست‌ها\n",
    "            y_true.extend([1] * len(anchor))  # جفت‌های مثبت\n",
    "            y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # تبدیل لیست‌ها به آرایه‌های numpy برای محاسبه معیارها\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # محاسبه معیارهای ارزیابی\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# استفاده از کد ارزیابی\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# فرض کنید که test_loader در دسترس باشد\n",
    "evaluate_triplet_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261cbda2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
