{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6cdb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mey\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Mey\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "C:\\Users\\Mey\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "C:\\Users\\Mey\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at google/vit-base-patch16-224 were not used when initializing ViTModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, Normalize\n",
    "from transformers import ViTModel\n",
    "from torch.optim import Adam\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. تعریف Dataset برای Triplet‌ها\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.classes = dataset.classes\n",
    "        self.class_to_indices = {cls: np.where(np.array(dataset.targets) == idx)[0] for idx, cls in enumerate(self.classes)}\n",
    "        self.transform = Compose([\n",
    "            Resize((224, 224)),  # تغییر اندازه تصاویر به 224x224\n",
    "            ToTensor(),  # تبدیل تصاویر به تانسور\n",
    "            Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # نرمال‌سازی\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_path, anchor_label = self.dataset.samples[idx]  # مسیر فایل و برچسب\n",
    "\n",
    "        # انتخاب Positive (همان کلاس)\n",
    "        positive_idx = np.random.choice(self.class_to_indices[self.classes[anchor_label]])\n",
    "        positive_path, _ = self.dataset.samples[positive_idx]\n",
    "\n",
    "        # انتخاب Negative (کلاس متفاوت)\n",
    "        negative_label = np.random.choice([cls for cls in self.classes if cls != self.classes[anchor_label]])\n",
    "        negative_idx = np.random.choice(self.class_to_indices[negative_label])\n",
    "        negative_path, _ = self.dataset.samples[negative_idx]\n",
    "\n",
    "        # پیش‌پردازش تصاویر\n",
    "        anchor_image = self.transform(Image.open(anchor_path).convert(\"RGB\"))\n",
    "        positive_image = self.transform(Image.open(positive_path).convert(\"RGB\"))\n",
    "        negative_image = self.transform(Image.open(negative_path).convert(\"RGB\"))\n",
    "\n",
    "        return anchor_image, positive_image, negative_image\n",
    "\n",
    "# 2. تعریف Attention Layer\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(feature_dim, feature_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feature_dim // 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, feature_dim)\n",
    "        attention_weights = self.attention(x)  # (batch_size, sequence_length, 1)\n",
    "        weighted_features = x * attention_weights  # (batch_size, sequence_length, feature_dim)\n",
    "        return weighted_features.sum(dim=1)  # (batch_size, feature_dim)\n",
    "\n",
    "# 3. تعریف مدل با Attention Mechanism\n",
    "class ViTWithAttention(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(ViTWithAttention, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained(model_name)\n",
    "        self.attention = AttentionLayer(self.vit.config.hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(x)\n",
    "        last_hidden_state = outputs.last_hidden_state  # (batch_size, sequence_length, hidden_size)\n",
    "        features = self.attention(last_hidden_state)  # (batch_size, hidden_size)\n",
    "        return features\n",
    "\n",
    "# 4. تعریف Triplet Loss\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        distance_positive = F.pairwise_distance(anchor, positive)\n",
    "        distance_negative = F.pairwise_distance(anchor, negative)\n",
    "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
    "        return losses.mean()\n",
    "\n",
    "# 5. بارگذاری داده‌ها از پوشه‌ها\n",
    "#data_dir = 'f:/Meysam-Khodarahi/PlantDiseaseDiagnosisFewShotLearning/siamese_triplet_net/src/dataset'\n",
    "data_dir = 'C:/Users/Mey/Documents/PlantDiseaseDiagnosisFewShotLearning/siamese_triplet_net/src/dataset'\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# بارگذاری داده‌ها با ImageFolder\n",
    "train_dataset = ImageFolder(train_dir)\n",
    "val_dataset = ImageFolder(val_dir)\n",
    "test_dataset = ImageFolder(test_dir)\n",
    "\n",
    "# ایجاد TripletDataset\n",
    "train_triplet_dataset = TripletDataset(train_dataset)\n",
    "train_loader = DataLoader(train_triplet_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 6. تعریف مدل، Optimizer و Loss Function\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "model = ViTWithAttention(model_name)\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "triplet_loss = TripletLoss(margin=1.0)\n",
    "\n",
    "# 7. آموزش مدل و محاسبه Accuracy\n",
    "num_epochs = 1\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        anchor, positive, negative = batch\n",
    "\n",
    "        # استخراج ویژگی‌ها (embeddings)\n",
    "        anchor_features = model(anchor)\n",
    "        positive_features = model(positive)\n",
    "        negative_features = model(negative)\n",
    "\n",
    "        # محاسبه‌ی loss\n",
    "        loss = triplet_loss(anchor_features, positive_features, negative_features)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # محاسبه accuracy\n",
    "        distance_positive = F.pairwise_distance(anchor_features, positive_features)\n",
    "        distance_negative = F.pairwise_distance(anchor_features, negative_features)\n",
    "        predictions = (distance_positive < distance_negative).float()  # 1 اگر درست، 0 اگر نادرست\n",
    "        correct += predictions.sum().item()\n",
    "        total += predictions.size(0)\n",
    "\n",
    "        # به‌روزرسانی مدل\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader)}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 8. ذخیره‌سازی مدل Fine-Tuned\n",
    "# torch.save(model.state_dict(), \"f:/Meysam-Khodarahi/PlantDiseaseDiagnosisFewShotLearning/siamese_triplet_net/vitWithAttentionState.pth\")\n",
    "# torch.save(model, \"f:/Meysam-Khodarahi/PlantDiseaseDiagnosisFewShotLearning/siamese_triplet_net/vitWithAttention.pth\")\n",
    "torch.save(model.state_dict(), \"C:/Users/Mey/Documents/PlantDiseaseDiagnosisFewShotLearning/siamese_triplet_net/vitWithAttentionState.pth\")\n",
    "torch.save(model, \"C:/Users/Mey/Documents/PlantDiseaseDiagnosisFewShotLearning/siamese_triplet_net/vitWithAttention.pth\")\n",
    "\n",
    "# 9. ارزیابی مدل و تجسم با t-SNE\n",
    "# def evaluate_model(model, dataloader):\n",
    "#     model.eval()\n",
    "#     all_features = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in dataloader:\n",
    "#             anchor, positive, negative = batch\n",
    "#             anchor_features = model(anchor)\n",
    "#             all_features.append(anchor_features.cpu().numpy())\n",
    "#             all_labels.append(np.zeros(anchor_features.shape[0]))  # برچسب‌های ساختگی برای تجسم\n",
    "\n",
    "#     all_features = np.concatenate(all_features, axis=0)\n",
    "#     all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "#     # کاهش ابعاد با t-SNE\n",
    "#     tsne = TSNE(n_components=2, random_state=42)\n",
    "#     tsne_results = tsne.fit_transform(all_features)\n",
    "\n",
    "#     # تجسم داده‌ها\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=all_labels, cmap='viridis', alpha=0.6)\n",
    "#     plt.colorbar()\n",
    "#     plt.title(\"t-SNE Visualization of Embeddings\")\n",
    "#     plt.show()\n",
    " \n",
    " \n",
    "# 9. ارزیابی مدل و تجسم با t-SNE\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            anchor, positive, negative = batch\n",
    "            anchor_features = model(anchor)\n",
    "            positive_features = model(positive)\n",
    "            negative_features = model(negative)\n",
    "\n",
    "            # جمع‌آوری ویژگی‌ها برای t-SNE\n",
    "            all_features.append(anchor_features.cpu().numpy())\n",
    "            all_labels.append(np.array([label for _, label in dataloader.dataset.dataset.samples]))\n",
    "\n",
    "            # محاسبه پیش‌بینی‌ها\n",
    "            distance_positive = F.pairwise_distance(anchor_features, positive_features)\n",
    "            distance_negative = F.pairwise_distance(anchor_features, negative_features)\n",
    "            predictions = (distance_positive < distance_negative).float().cpu().numpy()  # 1 اگر anchor و positive نزدیک‌تر باشند\n",
    "            all_predictions.append(predictions)\n",
    "\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "    # کاهش ابعاد با t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(all_features)\n",
    "\n",
    "    # تجسم داده‌ها\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=all_labels, cmap='viridis', alpha=0.6)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title(\"t-SNE Visualization of Embeddings\")\n",
    "    \n",
    "    # اضافه کردن legend برای کلاس‌ها\n",
    "    classes = dataloader.dataset.dataset.classes\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=plt.cm.viridis(i / (len(classes) - 1)), markersize=10) for i in range(len(classes))]\n",
    "    plt.legend(handles, classes, title=\"Classes\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # محاسبه معیارهای ارزیابی\n",
    "    true_labels = np.ones_like(all_predictions)  # برچسب‌های واقعی (همه ۱ هستند، زیرا anchor و positive متعلق به یک کلاس هستند)\n",
    "    accuracy = accuracy_score(true_labels, all_predictions)\n",
    "    precision = precision_score(true_labels, all_predictions)\n",
    "    recall = recall_score(true_labels, all_predictions)\n",
    "    f1 = f1_score(true_labels, all_predictions)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    " \n",
    "     \n",
    "    \n",
    "# ارزیابی مدل روی داده‌های تست\n",
    "test_triplet_dataset = TripletDataset(test_dataset)\n",
    "test_loader = DataLoader(test_triplet_dataset, batch_size=32, shuffle=False)\n",
    "evaluate_model(model, test_loader)\n",
    "\n",
    "# تعداد کلاس‌ها\n",
    "num_classes = len(test_dataset.classes)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "# ارزیابی مدل روی داده‌های تست\n",
    "test_triplet_dataset = TripletDataset(test_dataset)\n",
    "test_loader = DataLoader(test_triplet_dataset, batch_size=32, shuffle=False)\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156bd031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
