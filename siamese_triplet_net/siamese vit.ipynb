# نصب کتابخانه‌های مورد نیاز
#!pip install learn2learn
#!pip install efficientnet_pytorch
#!pip install transformers

from IPython.display import clear_output 
clear_output()
print('Done!')

import sys
sys.path.insert(0,'C:/Users/Mey/Documents/PlantDiseaseDiagnosisFewShotLearning/siamese_triplet_net/src/')
import torch
from transformers import ViTForImageClassification, ViTFeatureExtractor
from dataloaders import get_train_transforms, get_val_transforms, get_triplet_dataloader
from networks import TripletNet 
from models import MobileNetv2
from losses import TripletLoss
from trainer import fit
import torchvision

# مدل Siamese و ViT
embedding_net = MobileNetv2()
siamese_model = TripletNet(embedding_net=embedding_net)
vit_model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')
feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')

# تنظیمات بهینه‌ساز و یادگیری
optimizer = torch.optim.SGD(siamese_model.parameters(), lr=0.001, momentum=0.9)
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)
loss_fn = TripletLoss(1.)
n_epochs = 7
device = torch.cuda.is_available()

if device:
    siamese_model.cuda()
    vit_model.cuda()

log_interval = 10
path_data = 'C:/Users/Mey/Documents/PlantDiseaseDiagnosisFewShotLearning/siamese_triplet_net/src/dataset'

# بارگذاری داده‌ها
triplet_train_loader = get_triplet_dataloader(root=path_data + '/train/', batch_size=5, transforms=get_train_transforms())
triplet_val_loader = get_triplet_dataloader(root=path_data + '/val/', batch_size=5, transforms=get_val_transforms())

# آموزش مدل Siamese
fit(triplet_train_loader, triplet_val_loader, siamese_model, loss_fn, optimizer, lr_scheduler, n_epochs, device, log_interval)

# استخراج ویژگی‌ها با استفاده از مدل Siamese
def generate_embeddings(data_loader, model):
    with torch.no_grad():
        model.eval()
        embeddings = []
        labels = []
        for batch_imgs, batch_labels in data_loader:
            if device:
                batch_imgs = batch_imgs.cuda()
            batch_E = model.get_embedding(batch_imgs)
            embeddings.append(batch_E.cpu().numpy())
            labels.append(batch_labels.numpy())
    return np.concatenate(embeddings), np.concatenate(labels)

# بارگذاری داده‌های تست
test_data = torchvision.datasets.ImageFolder(root=path_data + '/test/', transform=get_val_transforms())
test_loader = torch.utils.data.DataLoader(test_data, batch_size=1)

# استخراج ویژگی‌ها از داده‌های تست
test_embeddings, test_labels = generate_embeddings(test_loader, siamese_model)

# طبقه‌بندی با استفاده از ViT
def classify_with_vit(embeddings, labels, vit_model, feature_extractor):
    vit_model.eval()
    predictions = []
    with torch.no_grad():
        for embedding in embeddings:
            inputs = feature_extractor(images=embedding, return_tensors="pt")
            if device:
                inputs = {k: v.cuda() for k, v in inputs.items()}
            outputs = vit_model(**inputs)
            logits = outputs.logits
            predicted_class = logits.argmax(-1).item()
            predictions.append(predicted_class)
    return predictions

# پیش‌بینی با ViT
predictions = classify_with_vit(test_embeddings, test_labels, vit_model, feature_extractor)

# ارزیابی نتایج
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy = accuracy_score(test_labels, predictions)
precision = precision_score(test_labels, predictions, average='macro')
recall = recall_score(test_labels, predictions, average='macro')
f1 = f1_score(test_labels, predictions, average='macro')

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')
